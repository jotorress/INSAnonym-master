{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anonymisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code par Jonathan Torres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script d'Anonymisation des Données avec Chiffrement et Randomisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Premier code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier anonymisé a été enregistré sous le nom anonymized_PLUS.csv.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "def generate_key():\n",
    "    \"\"\"Génère une clé pour le chiffrement.\"\"\"\n",
    "    return Fernet.generate_key()\n",
    "\n",
    "def encrypt_id(user_id, key):\n",
    "    \"\"\"Chiffre l'ID de l'utilisateur en utilisant la clé fournie.\"\"\"\n",
    "    fernet = Fernet(key)\n",
    "    user_id_bytes = str(user_id).encode()  # Convertir l'ID en octets\n",
    "    encrypted_id = fernet.encrypt(user_id_bytes)  # Chiffrer l'ID\n",
    "    return encrypted_id.decode()  # Retourner sous forme de chaîne\n",
    "\n",
    "def anonymize_data_with_consistency(input_file, output_file):\n",
    "    key = generate_key()  # Générer une clé pour le chiffrement\n",
    "    fernet = Fernet(key)  # Initialiser l'objet Fernet\n",
    "\n",
    "    def randomize_datetime(date_str):\n",
    "        \"\"\"Randomise la date et l'heure dans une plage variable, puis ajoute 2 heures et une valeur aléatoire entre 1 et 5 heures.\"\"\"\n",
    "        date_obj = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "        random_hours = random.randint(1, 5)  # Plage variable de 1 à 5 heures\n",
    "        randomized_date = date_obj + timedelta(hours=2 + random_hours)  # Ajouter 2 heures + heures aléatoires\n",
    "        return randomized_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    def modify_coordinates(coord, base_addition=1.5, variance=0.5):\n",
    "        \"\"\"Ajoute une valeur de base et une valeur aléatoire à la coordonnée, puis ajoute des zéros à la fin.\"\"\"\n",
    "        additional_value = random.uniform(0, variance)  # Valeur aléatoire entre 0 et 0.5\n",
    "        digit_addition = random.randint(10, 99)  # Nombre aléatoire entre 10 et 99\n",
    "        modified_coord = float(coord) + base_addition + additional_value + digit_addition\n",
    "        return f\"{modified_coord:.8f}0000000\"  # Ajouter sept zéros à la fin\n",
    "\n",
    "    with open(input_file, 'r') as infile:\n",
    "        reader = csv.reader(infile, delimiter='\\t')  # Lire le fichier CSV avec tabulation comme délimiteur\n",
    "        data = list(reader)\n",
    "\n",
    "    user_encrypted_ids = {}  # Dictionnaire pour associer les utilisateurs avec des IDs chiffrés\n",
    "    anonymized_data = []\n",
    "\n",
    "    # Première passe pour attribuer des IDs chiffrés\n",
    "    for row in data:\n",
    "        user_id = int(row[0])  # Identifier l'utilisateur original\n",
    "\n",
    "        if user_id not in user_encrypted_ids:\n",
    "            encrypted_id = encrypt_id(user_id, key)  # Chiffrer l'ID s'il n'existe pas\n",
    "            user_encrypted_ids[user_id] = encrypted_id  # Stocker l'ID chiffré\n",
    "\n",
    "    # Deuxième passe pour anonymiser les données\n",
    "    for row in data:\n",
    "        user_id = int(row[0])  # Identifier l'utilisateur original\n",
    "        encrypted_id = user_encrypted_ids[user_id]  # Obtenir l'ID chiffré correspondant\n",
    "\n",
    "        # Anonymiser les données\n",
    "        randomized_date = randomize_datetime(row[1])  # Modifier la date et l'heure\n",
    "        modified_latitude = modify_coordinates(row[2])  # Modifier la latitude\n",
    "        modified_longitude = modify_coordinates(row[3])  # Modifier la longitude\n",
    "\n",
    "        # Construire la ligne anonymisée\n",
    "        anonymized_row = [encrypted_id, randomized_date, modified_latitude, modified_longitude]\n",
    "        anonymized_data.append(anonymized_row)\n",
    "\n",
    "    # Enregistrer les données anonymisées dans un nouveau fichier\n",
    "    with open(output_file, 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter='\\t')\n",
    "        writer.writerows(anonymized_data)\n",
    "\n",
    "    # Enregistrer la clé pour le chiffrement\n",
    "    with open('encryption_key.key', 'wb') as key_file:\n",
    "        key_file.write(key)\n",
    "\n",
    "# Fichiers d'entrée et de sortie\n",
    "input_csv_file = 'input.csv'  # Chemin du fichier d'entrée\n",
    "output_csv_file = 'anonymized_PLUS.csv'  # Chemin du fichier de sortie\n",
    "\n",
    "# Exécuter la fonction\n",
    "anonymize_data_with_consistency(input_csv_file, output_csv_file)\n",
    "\n",
    "print(f\"Le fichier anonymisé a été enregistré sous le nom {output_csv_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deuxième Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo anonimizado se ha guardado como anonymized_PLUSTwo.csv.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "def generate_key():\n",
    "    \"\"\"Génère une clé pour le chiffrement.\"\"\"\n",
    "    return Fernet.generate_key()\n",
    "\n",
    "def encrypt(data, key):\n",
    "    \"\"\"Chiffre les données en utilisant la clé fournie.\"\"\"\n",
    "    fernet = Fernet(key)\n",
    "    data_bytes = str(data).encode()  # Convertir la donnée en octets\n",
    "    encrypted_data = fernet.encrypt(data_bytes)  # Chiffrer la donnée\n",
    "    return encrypted_data.decode()  # Retourner sous forme de chaîne\n",
    "\n",
    "def randomize_value(value, perturbation_range):\n",
    "    \"\"\"Perturbe une valeur aléatoirement dans une plage donnée.\"\"\"\n",
    "    perturbation = random.uniform(-perturbation_range, perturbation_range)\n",
    "    return float(value) + perturbation\n",
    "\n",
    "def randomize_datetime(date_str):\n",
    "    \"\"\"Randomise la date et l'heure dans une plage variable.\"\"\"\n",
    "    date_obj = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "    random_hours = random.randint(1, 5)  # Plage variable de 1 à 5 heures\n",
    "    randomized_date = date_obj + timedelta(hours=2 + random_hours)  # Ajouter 2 heures + heures aléatoires\n",
    "    return randomized_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def modify_coordinates(coord, base_addition=1.5, variance=0.5):\n",
    "    \"\"\"Ajoute une valeur de base et une valeur aléatoire à la coordonnée, puis ajoute des zéros à la fin.\"\"\"\n",
    "    additional_value = random.uniform(0, variance)  # Valeur aléatoire entre 0 et 0.5\n",
    "    digit_addition = random.randint(10, 99)  # Nombre aléatoire entre 10 et 99\n",
    "    modified_coord = float(coord) + base_addition + additional_value + digit_addition\n",
    "    return f\"{modified_coord:.8f}0000000\"  # Ajouter sept zéros à la fin\n",
    "\n",
    "def anonymize_data_with_consistency(input_file, output_file):\n",
    "    key = generate_key()  # Générer une clé pour le chiffrement\n",
    "    fernet = Fernet(key)  # Initialiser l'objet Fernet\n",
    "\n",
    "    with open(input_file, 'r') as infile:\n",
    "        reader = csv.reader(infile, delimiter='\\t')  # Lire le CSV avec tabulation comme délimiteur\n",
    "        data = list(reader)\n",
    "\n",
    "    user_encrypted_ids = {}  # Dictionnaire pour associer les utilisateurs avec des IDs chiffrés\n",
    "    anonymized_data = []\n",
    "\n",
    "    # Première passe pour assigner des IDs chiffrés\n",
    "    for row in data:\n",
    "        user_id = int(row[0])  # Identifier l'utilisateur original\n",
    "        if user_id not in user_encrypted_ids:\n",
    "            encrypted_id = encrypt(user_id, key)  # Chiffrer l'ID s'il n'existe pas\n",
    "            user_encrypted_ids[user_id] = encrypted_id  # Stocker l'ID chiffré\n",
    "\n",
    "    # Deuxième passe pour anonymiser les données\n",
    "    for row in data:\n",
    "        user_id = int(row[0])  # Identifier l'utilisateur original\n",
    "        encrypted_id = user_encrypted_ids[user_id]  # Obtenir l'ID chiffré correspondant\n",
    "\n",
    "        # Anonymiser les données\n",
    "        randomized_date = randomize_datetime(row[1])  # Modifier la date et l'heure\n",
    "        modified_latitude = modify_coordinates(row[2])  # Changer la latitude\n",
    "        modified_longitude = modify_coordinates(row[3])  # Changer la longitude\n",
    "\n",
    "        # Ici, vous pourriez ajouter plus de données à chiffrer ou randomiser\n",
    "        # Par exemple, si vous aviez un email ou un téléphone dans la ligne :\n",
    "        # encrypted_email = encrypt(row[4], key)  # Chiffrer l'email\n",
    "        # encrypted_phone = encrypt(row[5], key)  # Chiffrer le téléphone\n",
    "\n",
    "        # Construire la ligne anonymisée\n",
    "        anonymized_row = [encrypted_id, randomized_date, modified_latitude, modified_longitude]  # Ajouter plus de champs chiffrés ici\n",
    "        anonymized_data.append(anonymized_row)\n",
    "\n",
    "    # Sauvegarder les données anonymisées dans un nouveau fichier\n",
    "    with open(output_file, 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter='\\t')\n",
    "        writer.writerows(anonymized_data)\n",
    "\n",
    "    # Sauvegarder la clé pour le chiffrement\n",
    "    with open('encryption_key.key', 'wb') as key_file:\n",
    "        key_file.write(key)\n",
    "\n",
    "# Fichiers d'entrée et de sortie\n",
    "input_csv_file = 'input.csv'  # Chemin du fichier d'entrée\n",
    "output_csv_file = 'anonymized_PLUSTwo.csv'  # Chemin du fichier de sortie\n",
    "\n",
    "# Exécuter la fonction\n",
    "anonymize_data_with_consistency(input_csv_file, output_csv_file)\n",
    "\n",
    "print(f\"Le fichier anonymisé a été sauvegardé sous {output_csv_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison des différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Différence  \n",
    "\n",
    "| **Aspect**          | **Premier Code**                                       | **Deuxième Code**                                              |\n",
    "|----------------------|-------------------------------------------------------|---------------------------------------------------------------|\n",
    "| **Chiffrement**      | Spécifique aux IDs (`encrypt_id`).                     | Plus générique (`encrypt`) et réutilisable.                   |\n",
    "| **Randomisation**    | Opérations spécifiques pour les coordonnées et dates. | Inclut une fonction générale (`randomize_value`).             |\n",
    "| **Extensibilité**    | Plus limité (ne mentionne pas d'autres données).       | Préparé pour chiffrer d'autres données (emails, téléphones).  |\n",
    "| **Modularité**       | Fonctions spécifiques.                                | Fonctions réutilisables et génériques.                        |\n",
    "| **Usage Général**    | Axé sur l’anonymisation des IDs et des coordonnées.   | Plus flexible et adaptable pour d'autres données sensibles.   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaque par comparison de clefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def read_data(original_file, anonymized_file):\n",
    "    # Lire les données originales\n",
    "    original_data = pd.read_csv(original_file, sep=\"\\t\", header=None, names=[\"ID\", \"Date\", \"Latitude\", \"Longitude\"])\n",
    "    # Lire les données anonymisées\n",
    "    anonymized_data = pd.read_csv(anonymized_file, sep=\"\\t\", header=None, names=[\"ID\", \"Date\", \"Latitude\", \"Longitude\"])\n",
    "    return original_data, anonymized_data\n",
    "\n",
    "def calculate_sums(data):\n",
    "    # Convertir la colonne de date en datetime et extraire l'année et le numéro de semaine\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data['Year'] = data['Date'].dt.year\n",
    "    data['Week'] = data['Date'].dt.isocalendar().week\n",
    "    \n",
    "    # Grouper par ID, Année et Semaine, et sommer les coordonnées\n",
    "    sums = data.groupby(['ID', 'Year', 'Week']).agg({'Latitude': 'sum', 'Longitude': 'sum'}).reset_index()\n",
    "    return sums\n",
    "\n",
    "def generate_json(original_sums, anonymized_sums):\n",
    "    attack_data = {}\n",
    "    \n",
    "    # Parcourir chaque ID dans les données originales\n",
    "    for _, original_row in original_sums.iterrows():\n",
    "        original_id = original_row['ID']\n",
    "        year_week_key = f\"{original_row['Year']}-{original_row['Week']}\"\n",
    "        \n",
    "        if original_id not in attack_data:\n",
    "            attack_data[original_id] = {}\n",
    "        \n",
    "        if year_week_key not in attack_data[original_id]:\n",
    "            attack_data[original_id][year_week_key] = []\n",
    "        \n",
    "        # Trouver les identifiants anonymisés qui correspondent à la même semaine\n",
    "        anonymized_week_data = anonymized_sums[\n",
    "            (anonymized_sums['Year'] == original_row['Year']) &\n",
    "            (anonymized_sums['Week'] == original_row['Week'])\n",
    "        ]\n",
    "        \n",
    "        # Obtenir les IDs anonymisés pour la semaine actuelle\n",
    "        anonymized_ids = anonymized_week_data['ID'].unique()\n",
    "        \n",
    "        # Ajouter les IDs aux données d'attaque\n",
    "        attack_data[original_id][year_week_key].extend(anonymized_ids.tolist())\n",
    "    \n",
    "    return attack_data\n",
    "\n",
    "def main(original_file, anonymized_file, output_json_file):\n",
    "    original_data, anonymized_data = read_data(original_file, anonymized_file)\n",
    "    \n",
    "    # Calculer les sommes des coordonnées\n",
    "    original_sums = calculate_sums(original_data)\n",
    "    anonymized_sums = calculate_sums(anonymized_data)\n",
    "    \n",
    "    # Générer le JSON d'attaque\n",
    "    attack_data = generate_json(original_sums, anonymized_sums)\n",
    "    \n",
    "    # Sauvegarder le JSON dans un fichier\n",
    "    with open(output_json_file, 'w') as json_file:\n",
    "        json.dump(attack_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécuter le script\n",
    "if __name__ == \"__main__\":\n",
    "    original_file = 'input.csv'      # Fichier original\n",
    "    anonymized_file = 'anonymized_NewInputPlus.csv'  # Fichier anonymisés\n",
    "    output_json_file = 'attack_PLUS.json'    # Fichier de sortie JSON\n",
    "    \n",
    "    main(original_file, anonymized_file, output_json_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
